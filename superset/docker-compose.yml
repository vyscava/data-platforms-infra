name: superset-stack
services:  
  redis:
    image: redis:latest@sha256:47200b04138293fae39737e50878a238b13ec0781083126b1b0c63cf5d992e8d
    container_name: redis
    restart: unless-stopped
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    # Synology Container Manager uses as default log.db, however, due my fluentbit flow
    # I am reading logs from json files, flagging it here in the compose to force Synlogy 
    # to save logs the way I need them.
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  superset:
    build: /volume2/dockers/superset/
    hostname: superset
    container_name: superset
    restart: unless-stopped
    environment:
      POSTGRESS_HOSTNAME: ${POSTGRESS_HOSTNAME}
      POSTGRESS_HOSTNAME_PORT: ${POSTGRESS_HOSTNAME_PORT}
      PSQL_SUPERSET_USER: ${PSQL_SUPERSET_USER}
      PSQL_SUPERSET_PASSWORD: ${PSQL_SUPERSET_PASSWORD}
      PSQL_SUPERSET_DB: ${PSQL_SUPERSET_DB}
    ports:
      - "8088:8088"
    dns:
      - 192.168.50.4
    volumes:
      - superset-data:/app/superset_home
      - /volume2/dockers/superset/superset_config.py:/app/superset_config.py
    depends_on:
      redis:
        condition: service_healthy
    mem_limit: 4G
    # Synology Container Manager uses as default log.db, however, due my fluentbit flow
    # I am reading logs from json files, flagging it here in the compose to force Synlogy 
    # to save logs the way I need them.
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: 1G

volumes:
  superset-data:
    driver: local
  redis-data:
    driver: local
